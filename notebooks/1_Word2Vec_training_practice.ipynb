{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jdasam/aat3020-2023/blob/main/notebooks/1_Word2Vec_training_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12b8d45b",
      "metadata": {
        "id": "12b8d45b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebd23b43",
      "metadata": {
        "id": "ebd23b43",
        "outputId": "e2034f27-0f8d-48e0-dbd8-a88f7a919fe9",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-03-14 14:37:18--  https://raw.githubusercontent.com/amephraim/nlp/master/texts/J.%20K.%20Rowling%20-%20Harry%20Potter%201%20-%20Sorcerer's%20Stone.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 439742 (429K) [text/plain]\n",
            "Saving to: ‘J. K. Rowling - Harry Potter 1 - Sorcerer's Stone.txt.3’\n",
            "\n",
            "J. K. Rowling - Har 100%[===================>] 429.44K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2023-03-14 14:37:18 (8.10 MB/s) - ‘J. K. Rowling - Harry Potter 1 - Sorcerer's Stone.txt.3’ saved [439742/439742]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget \"https://raw.githubusercontent.com/amephraim/nlp/master/texts/J.%20K.%20Rowling%20-%20Harry%20Potter%201%20-%20Sorcerer's%20Stone.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "867a7ee6",
      "metadata": {
        "id": "867a7ee6"
      },
      "outputs": [],
      "source": [
        "def remove_punctuation(x):\n",
        "  return x.translate(''.maketrans('', '', string.punctuation))\n",
        "\n",
        "def make_tokenized_corpus(corpus):\n",
        "  out= [ [y.lower() for y in remove_punctuation(sentence).split(' ') if y] for sentence in corpus]\n",
        "  return [x for x in out if x!=[]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b55ee99",
      "metadata": {
        "id": "8b55ee99"
      },
      "outputs": [],
      "source": [
        "with open(\"J. K. Rowling - Harry Potter 1 - Sorcerer's Stone.txt\", 'r') as f:\n",
        "  strings = f.readlines()\n",
        "sample_text = \"\".join(strings).replace('\\n', ' ').replace('Mr.', 'mr').replace('Mrs.', 'mrs').split('. ')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6d40916",
      "metadata": {
        "id": "f6d40916",
        "outputId": "6954038f-5fcb-4bd4-a97a-e20e78839f3a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['they',\n",
              " 'were',\n",
              " 'the',\n",
              " 'last',\n",
              " 'people',\n",
              " 'youd',\n",
              " 'expect',\n",
              " 'to',\n",
              " 'be',\n",
              " 'involved',\n",
              " 'in',\n",
              " 'anything',\n",
              " 'strange',\n",
              " 'or',\n",
              " 'mysterious',\n",
              " 'because',\n",
              " 'they',\n",
              " 'just',\n",
              " 'didnt',\n",
              " 'hold',\n",
              " 'with',\n",
              " 'such',\n",
              " 'nonsense']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus = make_tokenized_corpus(sample_text)\n",
        "corpus[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f6a08e1",
      "metadata": {
        "id": "3f6a08e1",
        "outputId": "0c43b2f9-e933-4b46-9f5c-ddc37a4ae8d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num entire unique words: 6038\n",
            "Num entire unique words after filtering: 3450\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "def get_entire_words(corpus):\n",
        "  return sorted(list(set([y for x in corpus for y in x])))\n",
        "\n",
        "def word_to_idx(unique_word_list):\n",
        "  return {x:i for i, x in enumerate(unique_word_list)}\n",
        "\n",
        "entire_words = get_entire_words(corpus)\n",
        "print(f\"Num entire unique words: {len(entire_words)}\")\n",
        "# filter by min count\n",
        "word_counter = Counter([y for x in corpus for y in x])\n",
        "min_count = 2\n",
        "entire_words = [x for x in entire_words if word_counter[x] >= min_count]\n",
        "print(f\"Num entire unique words after filtering: {len(entire_words)}\")\n",
        "word_to_idx_dict = word_to_idx(entire_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d37905d5",
      "metadata": {
        "id": "d37905d5"
      },
      "outputs": [],
      "source": [
        "def make_word_pair(corpus, window_size=3):\n",
        "  pair_list = []\n",
        "  for sentence in corpus:\n",
        "    for i, word in enumerate(sentence):\n",
        "      for j in range(max(i-window_size, 0), min(i+window_size+1, len(sentence))):\n",
        "        if j==i:\n",
        "          continue\n",
        "        context_word = sentence[j]\n",
        "        pair_list.append((word, context_word))\n",
        "  return pair_list\n",
        "pair_list = make_word_pair(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7adb08c",
      "metadata": {
        "id": "c7adb08c"
      },
      "outputs": [],
      "source": [
        "def make_word_pair_for_cbow(corpus, window_size=3):\n",
        "  pair_list = []\n",
        "  for sentence in corpus:\n",
        "    for i, word in enumerate(sentence):\n",
        "      context_words_for_wrd = []\n",
        "      for j in range(max(i-window_size, 0), min(i+window_size+1, len(sentence))):\n",
        "        if j==i:\n",
        "          continue\n",
        "        context_word = sentence[j]\n",
        "        context_words_for_wrd.append(context_word)\n",
        "      pair_list.append((word, context_words_for_wrd))\n",
        "  return pair_list\n",
        "pair_list = make_word_pair_for_cbow(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7defa46",
      "metadata": {
        "id": "e7defa46",
        "outputId": "f193fdd8-8e7b-49aa-e2da-cdfc7bc19b40"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('harry', 'potter'),\n",
              " ('harry', 'and'),\n",
              " ('harry', 'the'),\n",
              " ('potter', 'harry'),\n",
              " ('potter', 'and'),\n",
              " ('potter', 'the'),\n",
              " ('potter', 'sorcerers'),\n",
              " ('and', 'harry'),\n",
              " ('and', 'potter'),\n",
              " ('and', 'the'),\n",
              " ('and', 'sorcerers'),\n",
              " ('and', 'stone'),\n",
              " ('the', 'harry'),\n",
              " ('the', 'potter'),\n",
              " ('the', 'and'),\n",
              " ('the', 'sorcerers'),\n",
              " ('the', 'stone'),\n",
              " ('the', 'chapter'),\n",
              " ('sorcerers', 'potter'),\n",
              " ('sorcerers', 'and')]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pair_list[:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b51aae4",
      "metadata": {
        "id": "1b51aae4",
        "outputId": "d4dc78f2-8319-443b-b442-cbbbb9f5501f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "409784"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(pair_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "806de36b",
      "metadata": {
        "id": "806de36b"
      },
      "outputs": [],
      "source": [
        "num_vocab = len(word_to_idx_dict)\n",
        "dim_emb = 50\n",
        "\n",
        "word_u_mat = torch.randn(num_vocab, dim_emb, requires_grad=True)\n",
        "word_v_mat = torch.randn(num_vocab, dim_emb, requires_grad=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "720609ec",
      "metadata": {
        "id": "720609ec",
        "outputId": "01a7ebe8-26a8-422e-fd10-f0d00c0c6f04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('harry', 'potter')\n",
            "2373 3827\n"
          ]
        }
      ],
      "source": [
        "pair = pair_list[0]\n",
        "print(pair)\n",
        "\n",
        "center_word = word_to_idx_dict[pair[0]]\n",
        "window_word = word_to_idx_dict[pair[1]]\n",
        "print(center_word, window_word)\n",
        "\n",
        "center_vec = word_v_mat[center_word]\n",
        "window_vec = word_u_mat[window_word]\n",
        "\n",
        "dot_product = (center_vec * window_vec).sum()\n",
        "\n",
        "on_entire_vocab = torch.matmul(center_vec, word_u_mat.T)\n",
        "prob = torch.exp(dot_product) / torch.exp(on_entire_vocab).sum(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6485c8f",
      "metadata": {
        "id": "e6485c8f",
        "outputId": "ba807d7a-8180-4ce6-ca0e-80bd94aefbe4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "total_log_prob = 0\n",
        "for i, pair in tqdm(enumerate(pair_list)):\n",
        "  center_word = word_to_idx_dict[pair[0]]\n",
        "  window_word = word_to_idx_dict[pair[1]]\n",
        "\n",
        "  center_vec = word_v_mat[center_word]\n",
        "  window_vec = word_u_mat[window_word]\n",
        "\n",
        "  dot_product = (center_vec * window_vec).sum()\n",
        "\n",
        "  on_entire_vocab = torch.matmul(center_vec, word_u_mat.T)\n",
        "  prob = torch.exp(dot_product) / torch.exp(on_entire_vocab).sum(0)\n",
        "  log_prob = -torch.log(prob+1e-8)\n",
        "  total_log_prob += log_prob.item()\n",
        "  break\n",
        "total_log_prob /= len(pair_list)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}