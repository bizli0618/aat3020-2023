{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jdasam/aat3020-2023/blob/main/notebooks/2_Named_entity_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45a2da87"
      },
      "source": [
        "# Named Entity Recognition\n",
        "- For a given word and its context window, estimate whether the given word is location or not"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11619f5d"
      },
      "source": [
        "# 1. Download dataset\n",
        "- CoNLL2003 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10a4faa3",
        "outputId": "db3b8002-7c22-4078-a8dd-89f5024cea3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-30 05:59:46--  https://data.deepai.org/conll2003.zip\n",
            "Resolving data.deepai.org (data.deepai.org)... 185.93.1.244, 2400:52e0:1a00::1069:1\n",
            "Connecting to data.deepai.org (data.deepai.org)|185.93.1.244|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 982975 (960K) [application/zip]\n",
            "Saving to: ‘conll2003.zip’\n",
            "\n",
            "conll2003.zip       100%[===================>] 959.94K  4.37MB/s    in 0.2s    \n",
            "\n",
            "2023-03-30 05:59:47 (4.37 MB/s) - ‘conll2003.zip’ saved [982975/982975]\n",
            "\n",
            "Archive:  conll2003.zip\n",
            "  inflating: metadata                \n",
            "  inflating: test.txt                \n",
            "  inflating: train.txt               \n",
            "  inflating: valid.txt               \n"
          ]
        }
      ],
      "source": [
        "!wget https://data.deepai.org/conll2003.zip # Download dataset\n",
        "!unzip conll2003.zip # Unzip dataset zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7643dde5"
      },
      "source": [
        "## 2. Preprocess Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d31874b2",
        "outputId": "722abb05-ae77-4547-d920-0bf676ae6d95"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['-DOCSTART- -X- -X- O',\n",
              " '',\n",
              " 'EU NNP B-NP B-ORG',\n",
              " 'rejects VBZ B-VP O',\n",
              " 'German JJ B-NP B-MISC',\n",
              " 'call NN I-NP O',\n",
              " 'to TO B-VP O',\n",
              " 'boycott VB I-VP O',\n",
              " 'British JJ B-NP B-MISC',\n",
              " 'lamb NN I-NP O',\n",
              " '. . O O',\n",
              " '',\n",
              " 'Peter NNP B-NP B-PER',\n",
              " 'Blackburn NNP I-NP I-PER',\n",
              " '',\n",
              " 'BRUSSELS NNP B-NP B-LOC',\n",
              " '1996-08-22 CD I-NP O',\n",
              " '',\n",
              " 'The DT B-NP O',\n",
              " 'European NNP I-NP B-ORG',\n",
              " 'Commission NNP I-NP I-ORG',\n",
              " 'said VBD B-VP O',\n",
              " 'on IN B-PP O',\n",
              " 'Thursday NNP B-NP O',\n",
              " 'it PRP B-NP O',\n",
              " 'disagreed VBD B-VP O',\n",
              " 'with IN B-PP O',\n",
              " 'German JJ B-NP B-MISC',\n",
              " 'advice NN I-NP O',\n",
              " 'to TO B-PP O',\n",
              " 'consumers NNS B-NP O',\n",
              " 'to TO B-VP O',\n",
              " 'shun VB I-VP O',\n",
              " 'British JJ B-NP B-MISC',\n",
              " 'lamb NN I-NP O',\n",
              " 'until IN B-SBAR O',\n",
              " 'scientists NNS B-NP O',\n",
              " 'determine VBP B-VP O',\n",
              " 'whether IN B-SBAR O',\n",
              " 'mad JJ B-NP O',\n",
              " 'cow NN I-NP O',\n",
              " 'disease NN I-NP O',\n",
              " 'can MD B-VP O',\n",
              " 'be VB I-VP O',\n",
              " 'transmitted VBN I-VP O',\n",
              " 'to TO B-PP O',\n",
              " 'sheep NN B-NP O',\n",
              " '. . O O',\n",
              " '',\n",
              " 'Germany NNP B-NP B-LOC',\n",
              " \"'s POS B-NP O\",\n",
              " 'representative NN I-NP O',\n",
              " 'to TO B-PP O',\n",
              " 'the DT B-NP O',\n",
              " 'European NNP I-NP B-ORG',\n",
              " 'Union NNP I-NP I-ORG',\n",
              " \"'s POS B-NP O\",\n",
              " 'veterinary JJ I-NP O',\n",
              " 'committee NN I-NP O',\n",
              " 'Werner NNP I-NP B-PER',\n",
              " 'Zwingmann NNP I-NP I-PER',\n",
              " 'said VBD B-VP O',\n",
              " 'on IN B-PP O',\n",
              " 'Wednesday NNP B-NP O',\n",
              " 'consumers NNS I-NP O',\n",
              " 'should MD B-VP O',\n",
              " 'buy VB I-VP O',\n",
              " 'sheepmeat NN B-NP O',\n",
              " 'from IN B-PP O',\n",
              " 'countries NNS B-NP O']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "with open(\"train.txt\") as f:\n",
        "  string = ''.join(f.readlines())\n",
        "dataset = string.split('\\n')\n",
        "\n",
        "dataset[:70]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "scrolled": true,
        "vscode": {
          "languageId": "python"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49e7f34b",
        "outputId": "a488e1ce-beb2-458d-9970-51f7f584e42b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['-DOCSTART- -X- -X- O'],\n",
              " ['EU NNP B-NP B-ORG',\n",
              "  'rejects VBZ B-VP O',\n",
              "  'German JJ B-NP B-MISC',\n",
              "  'call NN I-NP O',\n",
              "  'to TO B-VP O',\n",
              "  'boycott VB I-VP O',\n",
              "  'British JJ B-NP B-MISC',\n",
              "  'lamb NN I-NP O',\n",
              "  '. . O O'],\n",
              " ['Peter NNP B-NP B-PER', 'Blackburn NNP I-NP I-PER'],\n",
              " ['BRUSSELS NNP B-NP B-LOC', '1996-08-22 CD I-NP O'],\n",
              " ['The DT B-NP O',\n",
              "  'European NNP I-NP B-ORG',\n",
              "  'Commission NNP I-NP I-ORG',\n",
              "  'said VBD B-VP O',\n",
              "  'on IN B-PP O',\n",
              "  'Thursday NNP B-NP O',\n",
              "  'it PRP B-NP O',\n",
              "  'disagreed VBD B-VP O',\n",
              "  'with IN B-PP O',\n",
              "  'German JJ B-NP B-MISC',\n",
              "  'advice NN I-NP O',\n",
              "  'to TO B-PP O',\n",
              "  'consumers NNS B-NP O',\n",
              "  'to TO B-VP O',\n",
              "  'shun VB I-VP O',\n",
              "  'British JJ B-NP B-MISC',\n",
              "  'lamb NN I-NP O',\n",
              "  'until IN B-SBAR O',\n",
              "  'scientists NNS B-NP O',\n",
              "  'determine VBP B-VP O',\n",
              "  'whether IN B-SBAR O',\n",
              "  'mad JJ B-NP O',\n",
              "  'cow NN I-NP O',\n",
              "  'disease NN I-NP O',\n",
              "  'can MD B-VP O',\n",
              "  'be VB I-VP O',\n",
              "  'transmitted VBN I-VP O',\n",
              "  'to TO B-PP O',\n",
              "  'sheep NN B-NP O',\n",
              "  '. . O O']]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from itertools import groupby\n",
        "\n",
        "dataset_in_sentence = [list(group) for k, group in groupby(dataset, lambda x: x == \"\") if not k]\n",
        "dataset_in_sentence[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65c3dfa8",
        "outputId": "392fc6aa-e09a-49ff-fdb3-2e1bf30cedaa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10625"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# [len(sentence) for sentence in dataset_in_sentence]\n",
        "filtered_dataset = [sentence for sentence in dataset_in_sentence if len(sentence) > 5]\n",
        "len(filtered_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1a1714b",
        "outputId": "eda5a54d-0578-42f6-a7e7-522a447b3574"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EU B-ORG\n",
            "['<pad>', '<pad>', 'EU', 'rejects', 'German']\n",
            "rejects O\n",
            "['<pad>', 'EU', 'rejects', 'German', 'call']\n",
            "German B-MISC\n",
            "['EU', 'rejects', 'German', 'call', 'to']\n",
            "call O\n",
            "['rejects', 'German', 'call', 'to', 'boycott']\n",
            "to O\n",
            "['German', 'call', 'to', 'boycott', 'British']\n",
            "boycott O\n",
            "['call', 'to', 'boycott', 'British', 'lamb']\n",
            "British B-MISC\n",
            "['to', 'boycott', 'British', 'lamb', '.']\n",
            "lamb O\n",
            "['boycott', 'British', 'lamb', '.', '<pad>']\n",
            ". O\n",
            "['British', 'lamb', '.', '<pad>', '<pad>']\n"
          ]
        }
      ],
      "source": [
        "window_len = 2\n",
        "sentence = filtered_dataset[0]\n",
        "\n",
        "for i, word in enumerate(sentence):\n",
        "  # print(word)\n",
        "  splitted_word = word.split(' ')\n",
        "  # print(splitted_word)\n",
        "  center_word = splitted_word[0]\n",
        "  label = splitted_word[-1]\n",
        "  print(center_word, label)\n",
        "  is_organization = label in ['B-ORG', 'I-ORG']\n",
        "  # print(is_organization)\n",
        "  \n",
        "  prev_index = max(i - window_len, 0)\n",
        "  prev_words = sentence[prev_index:i]\n",
        "  prev_words = [word_str.split(' ')[0] for word_str in prev_words]\n",
        "\n",
        "  # print(prev_words)\n",
        "\n",
        "  next_index = i + window_len + 1\n",
        "  next_words = sentence[i+1:next_index]\n",
        "  # next_words = [sentence[next_index] ]\n",
        "  next_words = [word_str.split(' ')[0] for word_str in next_words]\n",
        "\n",
        "  # We have to add padding, if number of prev words or next words are shorter than expected\n",
        "  if len(prev_words) != window_len:\n",
        "    prev_words = ['<pad>'] * (window_len - len(prev_words)) + prev_words\n",
        "\n",
        "  if len(next_words) != window_len:\n",
        "    next_words = next_words + ['<pad>'] * (window_len - len(next_words))\n",
        "\n",
        "  concatenated_words = prev_words + [center_word] + next_words\n",
        "  print(concatenated_words)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader\n",
        "\n",
        "wrd2vec = gensim.downloader.load(\"glove-wiki-gigaword-300\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPO83i3UKV8C",
        "outputId": "5672a92c-c83e-4ff3-bc42-16b0c7039708"
      },
      "execution_count": 7,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 376.1/376.1MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(wrd2vec)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtVJXmXnLoN8",
        "outputId": "532c23c4-8e69-4d93-bf04-e8261393cf1f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400000"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "vec_dim = 300\n",
        "\n",
        "corresp_vectors = []\n",
        "for word in concatenated_words:\n",
        "  if word.lower() in wrd2vec: # if the word exists in wrd2vec vocab\n",
        "    vec = wrd2vec[word.lower()] # call corresponding vector \n",
        "    # vec = torch.tensor(vec)\n",
        "  else: # there is no matching word in wrd2vec vocab, such as <pad>\n",
        "    # vec = torch.zeros(vec_dim)\n",
        "    vec = np.zeros(vec_dim) # use zero vectors for that token (word)\n",
        "  corresp_vectors.append(vec)\n",
        "\n",
        "# cat_vector = torch.cat(corresp_vectors)\n",
        "cat_vector = torch.tensor(np.concatenate(corresp_vectors), dtype=torch.float)\n",
        "cat_vector.shape\n",
        "\n",
        "# torch.tensor(np.concatenate(corresp_vectors), dtype=torch.float).dtype"
      ],
      "metadata": {
        "id": "ZwM-cn5YLPgF",
        "outputId": "ebff8489-2882-4d27-8802-4f0ee3654cc1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1500])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cat_vector"
      ],
      "metadata": {
        "id": "iYWSoOy912_Y",
        "outputId": "db4441d6-2a2c-4c92-debf-502e3cdca4c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.4436, -0.2418,  0.2366,  ...,  0.0000,  0.0000,  0.0000])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pair of data sample (input) and the label (desired output)\n",
        "cat_vector, is_organization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wO8epL-1NaT_",
        "outputId": "ea30fcdf-7071-44e4-84f9-365f9661fdfa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([ 0.4436, -0.2418,  0.2366,  ...,  0.0000,  0.0000,  0.0000]), False)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Design Model"
      ],
      "metadata": {
        "id": "dc55cq4wNrgt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class OrgClassifier(nn.Module):\n",
        "  def __init__(self, input_dim=1500, hidden_size=32):\n",
        "    super().__init__()\n",
        "    self.layer1 = nn.Linear(in_features=input_dim, out_features=hidden_size)\n",
        "    self.layer2 = nn.Linear(in_features=hidden_size, out_features=1)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    hidden = self.layer1(x)\n",
        "    # hidden = torch.relu(hidden)\n",
        "    out = self.layer2(hidden)\n",
        "    return out.sigmoid()\n",
        "\n",
        "model = OrgClassifier()\n",
        "out = model(cat_vector)\n",
        "print(cat_vector.shape, out.shape, out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h04izZDGNaOV",
        "outputId": "70abddc8-0302-4806-8238-1e0bd29bb25a"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1500]) torch.Size([1]) tensor([0.4901], grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hidden = model.layer1(cat_vector)\n",
        "print(hidden)\n",
        "print(hidden.shape)\n",
        "hidden = torch.relu(hidden) # You have to put non-linear operation between layers\n",
        "print(hidden)\n",
        "out = model.layer2(hidden)\n",
        "print(out)\n",
        "print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwN-p4MOQhgW",
        "outputId": "25b4965b-d342-45ca-8edb-d31affd5f542"
      },
      "execution_count": 13,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([-0.2491, -0.0228, -0.0574,  0.1212, -0.2563,  0.0663,  0.0213, -0.0580,\n",
            "         0.0635, -0.0760,  0.1940, -0.1163,  0.2503, -0.0029, -0.0909, -0.0877,\n",
            "        -0.0345,  0.0385, -0.3809,  0.2882,  0.3045,  0.2356,  0.1071,  0.2397,\n",
            "         0.0620, -0.0417, -0.2147, -0.1061, -0.0287,  0.3428, -0.0850,  0.0490],\n",
            "       grad_fn=<AddBackward0>)\n",
            "torch.Size([32])\n",
            "tensor([0.0000, 0.0000, 0.0000, 0.1212, 0.0000, 0.0663, 0.0213, 0.0000, 0.0635,\n",
            "        0.0000, 0.1940, 0.0000, 0.2503, 0.0000, 0.0000, 0.0000, 0.0000, 0.0385,\n",
            "        0.0000, 0.2882, 0.3045, 0.2356, 0.1071, 0.2397, 0.0620, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.3428, 0.0000, 0.0490], grad_fn=<ReluBackward0>)\n",
            "tensor([0.0210], grad_fn=<AddBackward0>)\n",
            "torch.Size([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How nn.Linear works\n",
        "out = model.layer2(hidden)\n",
        "\n",
        "# Let's get the same value by matrix multiplication\n",
        "# model.layer2.weight, model.layer2.bias\n",
        "for param in model.layer2.named_parameters(): # you can call list of entire parameters\n",
        "# by amodule.parameters()\n",
        "  print(param)\n",
        "\n",
        "print(hidden.shape, model.layer2.weight.shape)\n",
        "hidden_mat = hidden.unsqueeze(0)\n",
        "print(hidden_mat, hidden_mat.shape)\n",
        "weighted_sum = torch.mm(hidden_mat, model.layer2.weight.T ) #torch.mm is much more strict than torch.matmul\n",
        "\n",
        "weighted_sum_forloop = 0\n",
        "for x, w in zip(hidden, model.layer2.weight[0]):\n",
        "  # print(x.item(), w.item())\n",
        "  weighted_input = x.item() * w.item()\n",
        "  weighted_sum_forloop += weighted_input\n",
        "\n",
        "print(weighted_sum_forloop, weighted_sum)\n",
        "\n",
        "print(model.layer2.bias)\n",
        "final_output = weighted_sum + model.layer2.bias\n",
        "print(final_output, out)"
      ],
      "metadata": {
        "id": "Dklob4vr2-lT",
        "outputId": "44cb7c9e-4c4e-4b68-be06-8e936f83aebd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('weight', Parameter containing:\n",
            "tensor([[ 0.0328, -0.1276,  0.1043,  0.0959, -0.0650,  0.0703, -0.0350, -0.0998,\n",
            "          0.0711,  0.1579,  0.0287, -0.1123, -0.1141,  0.1038, -0.0670, -0.0191,\n",
            "          0.0773, -0.0746, -0.1071,  0.0388, -0.1030,  0.1434,  0.1665,  0.1760,\n",
            "         -0.0822,  0.1651,  0.1281,  0.0240,  0.1304,  0.0334,  0.1076,  0.0342]],\n",
            "       requires_grad=True))\n",
            "('bias', Parameter containing:\n",
            "tensor([-0.0548], requires_grad=True))\n",
            "torch.Size([32]) torch.Size([1, 32])\n",
            "tensor([[0.0000, 0.0000, 0.0000, 0.1212, 0.0000, 0.0663, 0.0213, 0.0000, 0.0635,\n",
            "         0.0000, 0.1940, 0.0000, 0.2503, 0.0000, 0.0000, 0.0000, 0.0000, 0.0385,\n",
            "         0.0000, 0.2882, 0.3045, 0.2356, 0.1071, 0.2397, 0.0620, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.3428, 0.0000, 0.0490]],\n",
            "       grad_fn=<UnsqueezeBackward0>) torch.Size([1, 32])\n",
            "0.07585863541566704 tensor([[0.0759]], grad_fn=<MmBackward0>)\n",
            "Parameter containing:\n",
            "tensor([-0.0548], requires_grad=True)\n",
            "tensor([[0.0210]], grad_fn=<AddBackward0>) tensor([0.0210], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9H6lcPUJ5kFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "relu_hidden = torch.relu(hidden) \n",
        "relu_hidden = hidden.relu()\n",
        "\n",
        "torch.sigmoid(out) == out.sigmoid()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAdhowMHRb5l",
        "outputId": "dab4de27-df78-4043-fdcd-058768b9c5db"
      },
      "execution_count": 15,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([True])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make Dataset Class"
      ],
      "metadata": {
        "id": "fB96mYlESABp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset:\n",
        "  def __init__(self, txt_fn, wrd2vec):\n",
        "    dataset = self.read_text_data(txt_fn)\n",
        "    dataset_in_sentence = self.group_by_sentence(dataset)\n",
        "    filtered_dataset = [sentence for sentence in dataset_in_sentence if len(sentence) > 5]\n",
        "    self.data_in_sentence = filtered_dataset\n",
        "\n",
        "    # for every sentence, make windowed_words pairs:\n",
        "    total_windowed_words = []\n",
        "    for sentence in self.data_in_sentence:\n",
        "      total_windowed_words += self.get_windowed_words_from_sentence(sentence)\n",
        "    self.data = total_windowed_words\n",
        "    self.wrd2vec = wrd2vec \n",
        "    self.vec_size = wrd2vec.vector_size\n",
        "  \n",
        "  def read_text_data(self, txt_fn):\n",
        "    with open(\"train.txt\") as f:\n",
        "      string = ''.join(f.readlines())\n",
        "    dataset = string.split('\\n')\n",
        "    return dataset\n",
        "  \n",
        "  def group_by_sentence(self, dataset):\n",
        "    dataset_in_sentence = [list(group) for k, group in groupby(dataset, lambda x: x == \"\") if not k]\n",
        "    return dataset_in_sentence\n",
        "\n",
        "  def get_windowed_words_from_sentence(self, sentence):\n",
        "    result = []\n",
        "    for i, word in enumerate(sentence):\n",
        "      splitted_word = word.split(' ')\n",
        "      center_word = splitted_word[0]\n",
        "      label = splitted_word[-1]\n",
        "      is_organization = label in ['B-ORG', 'I-ORG']\n",
        "      \n",
        "      prev_index = max(i - window_len, 0)\n",
        "      prev_words = sentence[prev_index:i]\n",
        "      prev_words = [word_str.split(' ')[0] for word_str in prev_words]\n",
        "\n",
        "\n",
        "      next_index = i + window_len + 1\n",
        "      next_words = sentence[i+1:next_index]\n",
        "      next_words = [word_str.split(' ')[0] for word_str in next_words]\n",
        "\n",
        "      # We have to add padding, if number of prev words or next words are shorter than expected\n",
        "      if len(prev_words) != window_len:\n",
        "        prev_words = ['<pad>'] * (window_len - len(prev_words)) + prev_words\n",
        "\n",
        "      if len(next_words) != window_len:\n",
        "        next_words = next_words + ['<pad>'] * (window_len - len(next_words))\n",
        "\n",
        "      concatenated_words = prev_words + [center_word] + next_words\n",
        "      result.append( (concatenated_words, is_organization))\n",
        "    return result\n",
        "\n",
        "  def __len__(self): # number of independent data samples\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    # is called when you call dataset[idx]\n",
        "    cat_words, label = self.data[idx]\n",
        "\n",
        "    # return self.data[idx]\n",
        "    return self.convert_windowed_words_to_vector(cat_words), label\n",
        "\n",
        "  def convert_windowed_words_to_vector(self, cat_words):\n",
        "    # cat_words: list of strings\n",
        "    # e.g. ['<pad>', '<pad>', 'EU', 'rejects', 'German']\n",
        "    corresp_vectors = []\n",
        "    for word in cat_words:\n",
        "      if word.lower() in self.wrd2vec: # if the word exists in wrd2vec vocab\n",
        "        vec = self.wrd2vec[word.lower()] # call corresponding vector \n",
        "        # vec = torch.tensor(vec)\n",
        "      else: # there is no matching word in wrd2vec vocab, such as <pad>\n",
        "        # vec = torch.zeros(vec_dim)\n",
        "        vec = np.zeros(self.vec_size) # use zero vectors for that token (word)\n",
        "      corresp_vectors.append(vec)\n",
        "    return torch.tensor(np.concatenate(corresp_vectors), dtype=torch.float)\n",
        "\n",
        "dataset = Dataset(\"train.txt\", wrd2vec)"
      ],
      "metadata": {
        "id": "nPGbWxVWR_h1"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset.data), dataset.data[0]"
      ],
      "metadata": {
        "id": "hHUpjGUg9DJg",
        "outputId": "6a0a9ea9-cc12-4123-90aa-ff161060cfc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(192587, (['<pad>', '<pad>', 'EU', 'rejects', 'German'], True))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset), dataset[0]"
      ],
      "metadata": {
        "id": "mbFSkXTb9Sql",
        "outputId": "10536250-2099-4179-8bcf-2515f83025d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(192587,\n",
              " (tensor([ 0.0000,  0.0000,  0.0000,  ..., -0.1950,  0.2041,  0.3530]), True))"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[100]"
      ],
      "metadata": {
        "id": "TSWoHJco_-tY",
        "outputId": "7aaf7001-bdbc-4dbe-da38-7cc241480b56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-0.2295,  0.3255, -0.0927,  ..., -0.3422, -0.0224,  0.1368]), False)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wrd2vec.vector_size"
      ],
      "metadata": {
        "id": "Hahxf24x-9xL",
        "outputId": "9b75531d-45ec-4c51-b531-842474e5aec5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Our method can make training samples from a given data_in_setence\n",
        "dataset.get_windowed_words_from_sentence(dataset.data_in_sentence[100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGhz5RwYR3BZ",
        "outputId": "1b8ca163-9490-46e0-e8e8-1e578a912e10"
      },
      "execution_count": 21,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(['<pad>', '<pad>', 'Israel', \"'s\", 'Channel'], False),\n",
              " (['<pad>', 'Israel', \"'s\", 'Channel', 'Two'], False),\n",
              " (['Israel', \"'s\", 'Channel', 'Two', 'television'], True),\n",
              " ([\"'s\", 'Channel', 'Two', 'television', 'said'], True),\n",
              " (['Channel', 'Two', 'television', 'said', 'Damascus'], False),\n",
              " (['Two', 'television', 'said', 'Damascus', 'had'], False),\n",
              " (['television', 'said', 'Damascus', 'had', 'sent'], False),\n",
              " (['said', 'Damascus', 'had', 'sent', 'a'], False),\n",
              " (['Damascus', 'had', 'sent', 'a', '\"'], False),\n",
              " (['had', 'sent', 'a', '\"', 'calming'], False),\n",
              " (['sent', 'a', '\"', 'calming', 'signal'], False),\n",
              " (['a', '\"', 'calming', 'signal', '\"'], False),\n",
              " (['\"', 'calming', 'signal', '\"', 'to'], False),\n",
              " (['calming', 'signal', '\"', 'to', 'Israel'], False),\n",
              " (['signal', '\"', 'to', 'Israel', '.'], False),\n",
              " (['\"', 'to', 'Israel', '.', '<pad>'], False),\n",
              " (['to', 'Israel', '.', '<pad>', '<pad>'], False)]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# use data loader\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "dataloader = DataLoader(dataset, batch_size=16, shuffle=True, drop_last=True)\n",
        "\n",
        "for batch in dataloader:\n",
        "  print(batch)\n",
        "  break"
      ],
      "metadata": {
        "id": "2HcHg0-98Wr2",
        "outputId": "2c58c860-8713-4eeb-c4c4-f6582545d127",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tensor([[-0.0440,  0.4220, -0.0930,  ..., -0.5592, -0.4222, -0.1830],\n",
            "        [-0.6842,  0.5017, -0.1678,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.6490,  0.6189,  0.0786,  ..., -0.8461,  1.1838, -0.2312],\n",
            "        ...,\n",
            "        [ 0.0000,  0.0000,  0.0000,  ..., -0.3872, -0.6003,  0.1511],\n",
            "        [ 0.6187,  1.1583, -0.3718,  ..., -0.4354,  0.0656, -0.6171],\n",
            "        [-0.0824, -0.2031, -0.3797,  ...,  0.0000,  0.0000,  0.0000]]), tensor([False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensors = batch[0]\n",
        "labels = batch[1]\n",
        "\n",
        "input_tensors.shape, labels.shape"
      ],
      "metadata": {
        "id": "GbPDJK1WA0T2",
        "outputId": "056073f8-56da-494e-c37f-8675047d9b12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([16, 1500]), torch.Size([16]))"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check that our model can compute the input batch\n",
        "pred = model(input_tensors)\n",
        "pred.shape, pred"
      ],
      "metadata": {
        "id": "33zUbVYGBK2T",
        "outputId": "7fed0322-ff07-42fd-aac9-17272d745afd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([16, 1]),\n",
              " tensor([[0.4930],\n",
              "         [0.5074],\n",
              "         [0.5197],\n",
              "         [0.5250],\n",
              "         [0.5112],\n",
              "         [0.4849],\n",
              "         [0.5063],\n",
              "         [0.4905],\n",
              "         [0.5217],\n",
              "         [0.5167],\n",
              "         [0.5183],\n",
              "         [0.5045],\n",
              "         [0.5121],\n",
              "         [0.5083],\n",
              "         [0.5047],\n",
              "         [0.5007]], grad_fn=<SigmoidBackward0>))"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels.dtype, labels, labels.float()"
      ],
      "metadata": {
        "id": "4VwcsEDnDJwA",
        "outputId": "3ea55a33-74ed-4b80-95df-bc1716a1fe6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.bool,\n",
              " tensor([False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False]),\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pred)\n",
        "print(pred.squeeze())"
      ],
      "metadata": {
        "id": "n17fWx4IDgGQ",
        "outputId": "640e78e6-e16f-4abe-8cae-ff2105acdc97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4930],\n",
            "        [0.5074],\n",
            "        [0.5197],\n",
            "        [0.5250],\n",
            "        [0.5112],\n",
            "        [0.4849],\n",
            "        [0.5063],\n",
            "        [0.4905],\n",
            "        [0.5217],\n",
            "        [0.5167],\n",
            "        [0.5183],\n",
            "        [0.5045],\n",
            "        [0.5121],\n",
            "        [0.5083],\n",
            "        [0.5047],\n",
            "        [0.5007]], grad_fn=<SigmoidBackward0>)\n",
            "tensor([0.4930, 0.5074, 0.5197, 0.5250, 0.5112, 0.4849, 0.5063, 0.4905, 0.5217,\n",
            "        0.5167, 0.5183, 0.5045, 0.5121, 0.5083, 0.5047, 0.5007],\n",
            "       grad_fn=<SqueezeBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate loss\n",
        "print(pred.shape, labels.shape)\n",
        "\n",
        "def get_binary_cross_entropy_loss(pred, label, eps=1e-8):\n",
        "  return label * (-torch.log(pred+eps)) + (1-label) * (-torch.log(1-pred+eps))\n",
        "\n",
        "loss = get_binary_cross_entropy_loss(pred.squeeze(), labels.float())\n",
        "loss = loss.mean() # take mean\n",
        "loss"
      ],
      "metadata": {
        "id": "iiuVTxHBBbwx",
        "outputId": "af9fa215-0823-4d7d-87e5-eb0696e7746c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 1]) torch.Size([16])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check how gradient looks like before the backpropagation\n",
        "print(model.layer1.weight.grad) # print None"
      ],
      "metadata": {
        "id": "_5keVatqD5oY",
        "outputId": "0182ef95-73d1-47d4-82b5-30d685ad884f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# backpropagate the loss \n",
        "loss.backward()"
      ],
      "metadata": {
        "id": "z5PoLCdiDxqI"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check how gradient looks like after the backpropagation\n",
        "print(model.layer1.weight.grad)"
      ],
      "metadata": {
        "id": "LEbe0q7mEDEL",
        "outputId": "e48b1433-b3f8-424a-fd98-89fc2600fac5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 6.8121e-04,  1.9289e-03, -4.5691e-04,  ..., -1.3278e-03,\n",
            "         -2.5170e-03,  3.4391e-04],\n",
            "        [ 4.3482e-03, -7.6321e-03,  6.3110e-03,  ...,  7.8793e-03,\n",
            "         -3.2008e-04, -3.6359e-06],\n",
            "        [-3.9074e-03,  2.2323e-03, -1.2517e-03,  ...,  1.8737e-04,\n",
            "         -1.1051e-03,  6.6041e-05],\n",
            "        ...,\n",
            "        [ 1.2649e-03,  1.0731e-03, -1.4647e-03,  ..., -2.0625e-03,\n",
            "         -8.6817e-04,  1.1593e-03],\n",
            "        [-1.1284e-03,  4.8103e-03, -6.4542e-03,  ..., -1.2788e-02,\n",
            "         -3.9533e-03,  4.1493e-03],\n",
            "        [-8.1297e-04,  9.8327e-05, -5.1130e-04,  ..., -9.5175e-04,\n",
            "         -1.0588e-03,  3.4343e-04]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.layer1.weight.grad.shape, model.layer1.weight.shape\n",
        "# Each parameter in the layer has its own gradient"
      ],
      "metadata": {
        "id": "hdgqNLryEJSk",
        "outputId": "55a70d59-66ca-43ba-c906-c89e331db64b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([32, 1500]), torch.Size([32, 1500]))"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.layer1.weight.grad[0, :10]\n",
        "# Gradient is ratio between the parameter's change and the loss' change\n",
        "# if the gradient is 0.01\n",
        "# that means if the parameter increases for 1,\n",
        "# the loss will increase for 1*0.01"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eZYhpMeHjPG",
        "outputId": "0e331bbb-da12-475b-a336-297de9d6a0b0"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 6.8121e-04,  1.9289e-03, -4.5691e-04,  5.8656e-04,  2.2097e-04,\n",
              "        -7.3869e-04, -1.0776e-03, -1.3207e-03, -9.4426e-05, -2.8355e-03])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# manually update weight parameters using the gradient\n",
        "model.layer1.weight.data -= model.layer1.weight.grad * 0.001"
      ],
      "metadata": {
        "id": "Mn2aK17oEWl3"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use torch.optim.optimizers"
      ],
      "metadata": {
        "id": "twraLTiAEZdA"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model(input_tensors)\n",
        "loss = get_binary_cross_entropy_loss(pred.squeeze(), labels.float())\n",
        "loss = loss.mean()\n",
        "\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhgAM875HXTU",
        "outputId": "05bd5fe0-bb52-480b-a6d8-f9a5580e9032"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.70819091796875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.layer2.weight.grad = None # rest gradient to zero\n",
        "loss.backward()"
      ],
      "metadata": {
        "id": "-zcC1t5YJYYJ"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.layer2.weight.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWkIJQiZJjnY",
        "outputId": "8a511751-a53d-4e38-ca30-d5cd41457e36"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0185, 0.0596, 0.0494, 0.1009, 0.0147, 0.0248, 0.0316, 0.0277, 0.0260,\n",
              "         0.0244, 0.0551, 0.0471, 0.0318, 0.0411, 0.0241, 0.0245, 0.0363, 0.0416,\n",
              "         0.0089, 0.0313, 0.0538, 0.0156, 0.0314, 0.0422, 0.0253, 0.0629, 0.0259,\n",
              "         0.0615, 0.0304, 0.0386, 0.0871, 0.0265]])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.layer2.weight.data[0,-5])\n",
        "model.layer2.weight.data[0,-5] -= model.layer2.weight.grad[0,-5] * 100 # times learning rate\n",
        "print(model.layer2.weight.data[0,-5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9uPQQ1cJvH3",
        "outputId": "453d33d3-15ca-48b2-f148-565413e00baa"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-0.6519)\n",
            "tensor(-6.7970)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPIqbtG5KRVy",
        "outputId": "8f3de3cb-93fb-4aa9-e3c8-23c66db72f30"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([False, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "pred = model(input_tensors)\n",
        "loss = get_binary_cross_entropy_loss(pred.squeeze(), labels.float())\n",
        "loss = loss.mean()\n",
        "\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KVnVC4pJWPm",
        "outputId": "4899c236-6e97-4b3b-a478-5bf30036b952"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4724261462688446\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model == update the model's parameters\n",
        "\n",
        "# 1. make a prediction\n",
        "# 2. calculate the loss (to see how good or bad your current parameters are )\n",
        "# 3. calculate the gradient of each parameters using backpropagation\n",
        "# 4. update the parameters using the gradient (we call it optimization)\n",
        "# we can use several optimizers to update the parameters\n",
        "\n",
        "# optimizers: SGD (stochastic gradient descent, maybe Vanilla one), \n",
        "#    Adam (most famous), Adadelta, Adamp\n",
        "\n",
        "# Define optimizer\n",
        "# select the optimizer class\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "# now we can update the model's parameters using\n",
        "optimizer.step()\n",
        "\n",
        "# You can also reset the gradietn using the optimizer\n",
        "optimizer.zero_grad()"
      ],
      "metadata": {
        "id": "d-Nv3e88Kito"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Let's use GPU\n",
        "DEV = 'cuda'\n",
        "model = OrgClassifier()\n",
        "model.to(DEV) # model=model.to('cuda)\n",
        "# cuda is an NVIDIA GPU library\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_record_wo_relu = []\n",
        "\n",
        "dataloader = DataLoader(dataset, batch_size=128, shuffle=True, drop_last=True)\n",
        "\n",
        "\n",
        "for batch in tqdm(dataloader):\n",
        "  input_tensors, labels = batch\n",
        "  input_tensors = input_tensors.to(DEV)\n",
        "  labels = labels.to(DEV)\n",
        "  pred = model(input_tensors)\n",
        "  loss = get_binary_cross_entropy_loss(pred.squeeze(), labels.float())\n",
        "  loss = loss.mean()\n",
        "  loss.backward() # do backpropagation. This will calculate the gradient of each parameter\n",
        "  optimizer.step() # This will update the parameters using the gradient\n",
        "  optimizer.zero_grad()\n",
        "  # print(torch.sum(labels).item(), loss.item())\n",
        "  loss_record_wo_relu.append(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "7eb1ac3c53ea4288a23599d3db5cce3b",
            "19b895912730429483892a8c8e6d7d71",
            "84951c9aa46849829054451d4da4d467",
            "7296cedbb76747ffbbb0dfb6fed59b41",
            "905a33c27e0a4371a03736be7756b5c6",
            "4944397815ee417e87abc8522a9a1ef4",
            "1944a3fad4554bfabf649c8aaa1bb8a6",
            "ec83a6af7beb4855905d4e2e37d63008",
            "e6fa7467de7c41b6bbcc44ea6976fc92",
            "1baa2ed823e94a00a96ed32d2df85ad5",
            "e24bc4a0ac5c434195bbc41dabcad264"
          ]
        },
        "id": "aFRrG6PJL9HC",
        "outputId": "bf0c05c0-c7cd-48fd-be19-11f9404eebeb"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1504 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7eb1ac3c53ea4288a23599d3db5cce3b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(loss_record)\n",
        "plt.plot(loss_record_wo_relu)"
      ],
      "metadata": {
        "id": "QVvPc7ezP-bk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(input_tensors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dp-JysamQMT4",
        "outputId": "db7f6728-b190-441a-881b-4e1e8e84e565"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.log(torch.tensor([1e-100]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jAYcwifLJDf",
        "outputId": "2cac294c-6c5a-48d9-923c-3d8424208f5d"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-inf])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# nan losses go back to your parameters by making nan grad, and nan weight\n",
        "model.layer1.weight.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmQ6yEzHOgE1",
        "outputId": "03da10a0-842c-4f8a-e3f6-703af794e7d9"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
              "        [nan, nan, nan,  ..., nan, nan, nan],\n",
              "        [nan, nan, nan,  ..., nan, nan, nan],\n",
              "        ...,\n",
              "        [nan, nan, nan,  ..., nan, nan, nan],\n",
              "        [nan, nan, nan,  ..., nan, nan, nan],\n",
              "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "nbformat": 4,
    "nbformat_minor": 5,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7eb1ac3c53ea4288a23599d3db5cce3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_19b895912730429483892a8c8e6d7d71",
              "IPY_MODEL_84951c9aa46849829054451d4da4d467",
              "IPY_MODEL_7296cedbb76747ffbbb0dfb6fed59b41"
            ],
            "layout": "IPY_MODEL_905a33c27e0a4371a03736be7756b5c6"
          }
        },
        "19b895912730429483892a8c8e6d7d71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4944397815ee417e87abc8522a9a1ef4",
            "placeholder": "​",
            "style": "IPY_MODEL_1944a3fad4554bfabf649c8aaa1bb8a6",
            "value": "100%"
          }
        },
        "84951c9aa46849829054451d4da4d467": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec83a6af7beb4855905d4e2e37d63008",
            "max": 1504,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e6fa7467de7c41b6bbcc44ea6976fc92",
            "value": 1504
          }
        },
        "7296cedbb76747ffbbb0dfb6fed59b41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1baa2ed823e94a00a96ed32d2df85ad5",
            "placeholder": "​",
            "style": "IPY_MODEL_e24bc4a0ac5c434195bbc41dabcad264",
            "value": " 1504/1504 [00:14&lt;00:00, 61.42it/s]"
          }
        },
        "905a33c27e0a4371a03736be7756b5c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4944397815ee417e87abc8522a9a1ef4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1944a3fad4554bfabf649c8aaa1bb8a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec83a6af7beb4855905d4e2e37d63008": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6fa7467de7c41b6bbcc44ea6976fc92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1baa2ed823e94a00a96ed32d2df85ad5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e24bc4a0ac5c434195bbc41dabcad264": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}