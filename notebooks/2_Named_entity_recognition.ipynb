{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jdasam/aat3020-2023/blob/main/notebooks/2_Named_entity_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45a2da87"
      },
      "source": [
        "# Named Entity Recognition\n",
        "- For a given word and its context window, estimate whether the given word is location or not"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11619f5d"
      },
      "source": [
        "# 1. Download dataset\n",
        "- CoNLL2003 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10a4faa3",
        "outputId": "a2d9cfe7-0986-4740-d5c5-8e7bc62b68b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-28 06:07:10--  https://data.deepai.org/conll2003.zip\n",
            "Resolving data.deepai.org (data.deepai.org)... 156.146.56.169, 2400:52e0:1500::977:1\n",
            "Connecting to data.deepai.org (data.deepai.org)|156.146.56.169|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 982975 (960K) [application/zip]\n",
            "Saving to: ‘conll2003.zip’\n",
            "\n",
            "\rconll2003.zip         0%[                    ]       0  --.-KB/s               \rconll2003.zip       100%[===================>] 959.94K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2023-03-28 06:07:10 (74.4 MB/s) - ‘conll2003.zip’ saved [982975/982975]\n",
            "\n",
            "Archive:  conll2003.zip\n",
            "  inflating: metadata                \n",
            "  inflating: test.txt                \n",
            "  inflating: train.txt               \n",
            "  inflating: valid.txt               \n"
          ]
        }
      ],
      "source": [
        "!wget https://data.deepai.org/conll2003.zip # Download dataset\n",
        "!unzip conll2003.zip # Unzip dataset zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7643dde5"
      },
      "source": [
        "## 2. Preprocess Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d31874b2",
        "outputId": "5a37ef22-967d-423e-add7-f2afe0ed4e0a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['-DOCSTART- -X- -X- O',\n",
              " '',\n",
              " 'EU NNP B-NP B-ORG',\n",
              " 'rejects VBZ B-VP O',\n",
              " 'German JJ B-NP B-MISC',\n",
              " 'call NN I-NP O',\n",
              " 'to TO B-VP O',\n",
              " 'boycott VB I-VP O',\n",
              " 'British JJ B-NP B-MISC',\n",
              " 'lamb NN I-NP O',\n",
              " '. . O O',\n",
              " '',\n",
              " 'Peter NNP B-NP B-PER',\n",
              " 'Blackburn NNP I-NP I-PER',\n",
              " '',\n",
              " 'BRUSSELS NNP B-NP B-LOC',\n",
              " '1996-08-22 CD I-NP O',\n",
              " '',\n",
              " 'The DT B-NP O',\n",
              " 'European NNP I-NP B-ORG',\n",
              " 'Commission NNP I-NP I-ORG',\n",
              " 'said VBD B-VP O',\n",
              " 'on IN B-PP O',\n",
              " 'Thursday NNP B-NP O',\n",
              " 'it PRP B-NP O',\n",
              " 'disagreed VBD B-VP O',\n",
              " 'with IN B-PP O',\n",
              " 'German JJ B-NP B-MISC',\n",
              " 'advice NN I-NP O',\n",
              " 'to TO B-PP O',\n",
              " 'consumers NNS B-NP O',\n",
              " 'to TO B-VP O',\n",
              " 'shun VB I-VP O',\n",
              " 'British JJ B-NP B-MISC',\n",
              " 'lamb NN I-NP O',\n",
              " 'until IN B-SBAR O',\n",
              " 'scientists NNS B-NP O',\n",
              " 'determine VBP B-VP O',\n",
              " 'whether IN B-SBAR O',\n",
              " 'mad JJ B-NP O',\n",
              " 'cow NN I-NP O',\n",
              " 'disease NN I-NP O',\n",
              " 'can MD B-VP O',\n",
              " 'be VB I-VP O',\n",
              " 'transmitted VBN I-VP O',\n",
              " 'to TO B-PP O',\n",
              " 'sheep NN B-NP O',\n",
              " '. . O O',\n",
              " '',\n",
              " 'Germany NNP B-NP B-LOC',\n",
              " \"'s POS B-NP O\",\n",
              " 'representative NN I-NP O',\n",
              " 'to TO B-PP O',\n",
              " 'the DT B-NP O',\n",
              " 'European NNP I-NP B-ORG',\n",
              " 'Union NNP I-NP I-ORG',\n",
              " \"'s POS B-NP O\",\n",
              " 'veterinary JJ I-NP O',\n",
              " 'committee NN I-NP O',\n",
              " 'Werner NNP I-NP B-PER',\n",
              " 'Zwingmann NNP I-NP I-PER',\n",
              " 'said VBD B-VP O',\n",
              " 'on IN B-PP O',\n",
              " 'Wednesday NNP B-NP O',\n",
              " 'consumers NNS I-NP O',\n",
              " 'should MD B-VP O',\n",
              " 'buy VB I-VP O',\n",
              " 'sheepmeat NN B-NP O',\n",
              " 'from IN B-PP O',\n",
              " 'countries NNS B-NP O']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "with open(\"train.txt\") as f:\n",
        "  string = ''.join(f.readlines())\n",
        "dataset = string.split('\\n')\n",
        "\n",
        "dataset[:70]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "scrolled": true,
        "vscode": {
          "languageId": "python"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49e7f34b",
        "outputId": "2ae4b896-45cf-4dd1-fc5b-78d061b50a8f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['-DOCSTART- -X- -X- O'],\n",
              " ['EU NNP B-NP B-ORG',\n",
              "  'rejects VBZ B-VP O',\n",
              "  'German JJ B-NP B-MISC',\n",
              "  'call NN I-NP O',\n",
              "  'to TO B-VP O',\n",
              "  'boycott VB I-VP O',\n",
              "  'British JJ B-NP B-MISC',\n",
              "  'lamb NN I-NP O',\n",
              "  '. . O O'],\n",
              " ['Peter NNP B-NP B-PER', 'Blackburn NNP I-NP I-PER'],\n",
              " ['BRUSSELS NNP B-NP B-LOC', '1996-08-22 CD I-NP O'],\n",
              " ['The DT B-NP O',\n",
              "  'European NNP I-NP B-ORG',\n",
              "  'Commission NNP I-NP I-ORG',\n",
              "  'said VBD B-VP O',\n",
              "  'on IN B-PP O',\n",
              "  'Thursday NNP B-NP O',\n",
              "  'it PRP B-NP O',\n",
              "  'disagreed VBD B-VP O',\n",
              "  'with IN B-PP O',\n",
              "  'German JJ B-NP B-MISC',\n",
              "  'advice NN I-NP O',\n",
              "  'to TO B-PP O',\n",
              "  'consumers NNS B-NP O',\n",
              "  'to TO B-VP O',\n",
              "  'shun VB I-VP O',\n",
              "  'British JJ B-NP B-MISC',\n",
              "  'lamb NN I-NP O',\n",
              "  'until IN B-SBAR O',\n",
              "  'scientists NNS B-NP O',\n",
              "  'determine VBP B-VP O',\n",
              "  'whether IN B-SBAR O',\n",
              "  'mad JJ B-NP O',\n",
              "  'cow NN I-NP O',\n",
              "  'disease NN I-NP O',\n",
              "  'can MD B-VP O',\n",
              "  'be VB I-VP O',\n",
              "  'transmitted VBN I-VP O',\n",
              "  'to TO B-PP O',\n",
              "  'sheep NN B-NP O',\n",
              "  '. . O O']]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "from itertools import groupby\n",
        "\n",
        "dataset_in_sentence = [list(group) for k, group in groupby(dataset, lambda x: x == \"\") if not k]\n",
        "dataset_in_sentence[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65c3dfa8",
        "outputId": "7752ccd4-dcb9-4f55-e46c-581c8ad93e0a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10625"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# [len(sentence) for sentence in dataset_in_sentence]\n",
        "filtered_dataset = [sentence for sentence in dataset_in_sentence if len(sentence) > 5]\n",
        "len(filtered_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1a1714b",
        "outputId": "027077f1-662a-4712-92ea-8908a1b25361"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EU B-ORG\n",
            "['<pad>', '<pad>', 'EU', 'rejects', 'German']\n",
            "rejects O\n",
            "['<pad>', 'EU', 'rejects', 'German', 'call']\n",
            "German B-MISC\n",
            "['EU', 'rejects', 'German', 'call', 'to']\n",
            "call O\n",
            "['rejects', 'German', 'call', 'to', 'boycott']\n",
            "to O\n",
            "['German', 'call', 'to', 'boycott', 'British']\n",
            "boycott O\n",
            "['call', 'to', 'boycott', 'British', 'lamb']\n",
            "British B-MISC\n",
            "['to', 'boycott', 'British', 'lamb', '.']\n",
            "lamb O\n",
            "['boycott', 'British', 'lamb', '.', '<pad>']\n",
            ". O\n",
            "['British', 'lamb', '.', '<pad>', '<pad>']\n"
          ]
        }
      ],
      "source": [
        "window_len = 2\n",
        "sentence = filtered_dataset[0]\n",
        "\n",
        "for i, word in enumerate(sentence):\n",
        "  # print(word)\n",
        "  splitted_word = word.split(' ')\n",
        "  # print(splitted_word)\n",
        "  center_word = splitted_word[0]\n",
        "  label = splitted_word[-1]\n",
        "  print(center_word, label)\n",
        "  is_organization = label in ['B-ORG', 'I-ORG']\n",
        "  # print(is_organization)\n",
        "  \n",
        "  prev_index = max(i - window_len, 0)\n",
        "  prev_words = sentence[prev_index:i]\n",
        "  prev_words = [word_str.split(' ')[0] for word_str in prev_words]\n",
        "\n",
        "  # print(prev_words)\n",
        "\n",
        "  next_index = i + window_len + 1\n",
        "  next_words = sentence[i+1:next_index]\n",
        "  # next_words = [sentence[next_index] ]\n",
        "  next_words = [word_str.split(' ')[0] for word_str in next_words]\n",
        "\n",
        "  # We have to add padding, if number of prev words or next words are shorter than expected\n",
        "  if len(prev_words) != window_len:\n",
        "    prev_words = ['<pad>'] * (window_len - len(prev_words)) + prev_words\n",
        "\n",
        "  if len(next_words) != window_len:\n",
        "    next_words = next_words + ['<pad>'] * (window_len - len(next_words))\n",
        "\n",
        "  concatenated_words = prev_words + [center_word] + next_words\n",
        "  print(concatenated_words)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader\n",
        "\n",
        "wrd2vec = gensim.downloader.load(\"glove-wiki-gigaword-300\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPO83i3UKV8C",
        "outputId": "db9fe511-8ec2-470f-fd10-abc5578db2db"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 376.1/376.1MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(wrd2vec)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtVJXmXnLoN8",
        "outputId": "3c78fc0b-2402-482c-dbef-8ea30b5ef497"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400000"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "vec_dim = 300\n",
        "\n",
        "corresp_vectors = []\n",
        "for word in concatenated_words:\n",
        "  if word.lower() in wrd2vec: # if the word exists in wrd2vec vocab\n",
        "    vec = wrd2vec[word.lower()] # call corresponding vector \n",
        "    # vec = torch.tensor(vec)\n",
        "  else: # there is no matching word in wrd2vec vocab, such as <pad>\n",
        "    # vec = torch.zeros(vec_dim)\n",
        "    vec = np.zeros(vec_dim) # use zero vectors for that token (word)\n",
        "  corresp_vectors.append(vec)\n",
        "\n",
        "# cat_vector = torch.cat(corresp_vectors)\n",
        "cat_vector = torch.tensor(np.concatenate(corresp_vectors), dtype=torch.float)\n",
        "cat_vector.shape\n",
        "\n",
        "# torch.tensor(np.concatenate(corresp_vectors), dtype=torch.float).dtype"
      ],
      "metadata": {
        "id": "ZwM-cn5YLPgF",
        "outputId": "84b1c405-e19a-453a-aa8e-a908d08f6fd8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1500])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cat_vector"
      ],
      "metadata": {
        "id": "iYWSoOy912_Y",
        "outputId": "6d8b692d-9bda-4633-fa38-514747c3a9f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.4436, -0.2418,  0.2366,  ...,  0.0000,  0.0000,  0.0000])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pair of data sample (input) and the label (desired output)\n",
        "cat_vector, is_organization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wO8epL-1NaT_",
        "outputId": "c5a7dea7-6178-462d-9d58-fe62454ac613"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 0.4436, -0.2418,  0.2366,  ...,  0.0000,  0.0000,  0.0000]), False)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Design Model"
      ],
      "metadata": {
        "id": "dc55cq4wNrgt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class OrgClassifier(nn.Module):\n",
        "  def __init__(self, input_dim=1500, hidden_size=32):\n",
        "    super().__init__()\n",
        "    self.layer1 = nn.Linear(in_features=input_dim, out_features=hidden_size)\n",
        "    self.layer2 = nn.Linear(in_features=hidden_size, out_features=1)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    hidden = self.layer1(x)\n",
        "    hidden = torch.relu(hidden)\n",
        "    out = self.layer2(hidden)\n",
        "    return out.sigmoid()\n",
        "\n",
        "model = OrgClassifier()\n",
        "out = model(cat_vector)\n",
        "print(cat_vector.shape, out.shape, out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h04izZDGNaOV",
        "outputId": "425fe9d6-c981-459d-a507-0119e89fd39c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1500]) torch.Size([1]) tensor([0.4609], grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hidden = model.layer1(cat_vector)\n",
        "print(hidden)\n",
        "print(hidden.shape)\n",
        "hidden = torch.relu(hidden) # You have to put non-linear operation between layers\n",
        "print(hidden)\n",
        "out = model.layer2(hidden)\n",
        "print(out)\n",
        "print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwN-p4MOQhgW",
        "outputId": "414114df-b860-46ff-ae3a-0ca7e52fd070"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.0178, -0.2095, -0.3372,  0.1973,  0.0235, -0.1307,  0.1096, -0.3513,\n",
            "         0.0741, -0.1546, -0.1529, -0.1720,  0.0741,  0.2228,  0.3113, -0.0898,\n",
            "        -0.1379,  0.2494,  0.1218, -0.0782,  0.0012,  0.0158, -0.0357, -0.1224,\n",
            "        -0.1205, -0.0797,  0.1083, -0.0118,  0.2305,  0.1643, -0.0163,  0.1856],\n",
            "       grad_fn=<AddBackward0>)\n",
            "torch.Size([32])\n",
            "tensor([0.0000, 0.0000, 0.0000, 0.1973, 0.0235, 0.0000, 0.1096, 0.0000, 0.0741,\n",
            "        0.0000, 0.0000, 0.0000, 0.0741, 0.2228, 0.3113, 0.0000, 0.0000, 0.2494,\n",
            "        0.1218, 0.0000, 0.0012, 0.0158, 0.0000, 0.0000, 0.0000, 0.0000, 0.1083,\n",
            "        0.0000, 0.2305, 0.1643, 0.0000, 0.1856], grad_fn=<ReluBackward0>)\n",
            "tensor([-0.1568], grad_fn=<AddBackward0>)\n",
            "torch.Size([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How nn.Linear works\n",
        "out = model.layer2(hidden)\n",
        "\n",
        "# Let's get the same value by matrix multiplication\n",
        "# model.layer2.weight, model.layer2.bias\n",
        "for param in model.layer2.named_parameters(): # you can call list of entire parameters\n",
        "# by amodule.parameters()\n",
        "  print(param)\n",
        "\n",
        "print(hidden.shape, model.layer2.weight.shape)\n",
        "hidden_mat = hidden.unsqueeze(0)\n",
        "print(hidden_mat, hidden_mat.shape)\n",
        "weighted_sum = torch.mm(hidden_mat, model.layer2.weight.T ) #torch.mm is much more strict than torch.matmul\n",
        "\n",
        "weighted_sum_forloop = 0\n",
        "for x, w in zip(hidden, model.layer2.weight[0]):\n",
        "  # print(x.item(), w.item())\n",
        "  weighted_input = x.item() * w.item()\n",
        "  weighted_sum_forloop += weighted_input\n",
        "\n",
        "print(weighted_sum_forloop, weighted_sum)\n",
        "\n",
        "print(model.layer2.bias)\n",
        "final_output = weighted_sum + model.layer2.bias\n",
        "print(final_output, out)"
      ],
      "metadata": {
        "id": "Dklob4vr2-lT",
        "outputId": "15240e4c-d6db-4cec-dac6-f991d61a8ae7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('weight', Parameter containing:\n",
            "tensor([[-0.1497,  0.1098,  0.0792,  0.1644, -0.0683, -0.0363,  0.0626,  0.1616,\n",
            "          0.0830,  0.0584,  0.0949, -0.0562,  0.1452, -0.0965, -0.1577,  0.1127,\n",
            "         -0.1460,  0.0594,  0.1732,  0.1479,  0.1643, -0.0771,  0.1436, -0.0760,\n",
            "         -0.1402, -0.1011,  0.0470,  0.0520, -0.0498,  0.1345, -0.0660, -0.0856]],\n",
            "       requires_grad=True))\n",
            "('bias', Parameter containing:\n",
            "tensor([-0.1756], requires_grad=True))\n",
            "torch.Size([32]) torch.Size([1, 32])\n",
            "tensor([[0.0000, 0.0000, 0.0000, 0.1973, 0.0235, 0.0000, 0.1096, 0.0000, 0.0741,\n",
            "         0.0000, 0.0000, 0.0000, 0.0741, 0.2228, 0.3113, 0.0000, 0.0000, 0.2494,\n",
            "         0.1218, 0.0000, 0.0012, 0.0158, 0.0000, 0.0000, 0.0000, 0.0000, 0.1083,\n",
            "         0.0000, 0.2305, 0.1643, 0.0000, 0.1856]],\n",
            "       grad_fn=<UnsqueezeBackward0>) torch.Size([1, 32])\n",
            "0.01875207416171904 tensor([[0.0188]], grad_fn=<MmBackward0>)\n",
            "Parameter containing:\n",
            "tensor([-0.1756], requires_grad=True)\n",
            "tensor([[-0.1568]], grad_fn=<AddBackward0>) tensor([-0.1568], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9H6lcPUJ5kFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "relu_hidden = torch.relu(hidden) \n",
        "relu_hidden = hidden.relu()\n",
        "\n",
        "torch.sigmoid(out) == out.sigmoid()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAdhowMHRb5l",
        "outputId": "01cefb85-6875-4fbb-d781-2b8f542f9c85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([True])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make Dataset Class"
      ],
      "metadata": {
        "id": "fB96mYlESABp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset:\n",
        "  def __init__(self, txt_fn, wrd2vec):\n",
        "    dataset = self.read_text_data(txt_fn)\n",
        "    dataset_in_sentence = self.group_by_sentence(dataset)\n",
        "    filtered_dataset = [sentence for sentence in dataset_in_sentence if len(sentence) > 5]\n",
        "    self.data_in_sentence = filtered_dataset\n",
        "\n",
        "    # for every sentence, make windowed_words pairs:\n",
        "    total_windowed_words = []\n",
        "    for sentence in self.data_in_sentence:\n",
        "      total_windowed_words += self.get_windowed_words_from_sentence(sentence)\n",
        "    self.data = total_windowed_words\n",
        "    self.wrd2vec = wrd2vec \n",
        "    self.vec_size = wrd2vec.vector_size\n",
        "  \n",
        "  def read_text_data(self, txt_fn):\n",
        "    with open(\"train.txt\") as f:\n",
        "      string = ''.join(f.readlines())\n",
        "    dataset = string.split('\\n')\n",
        "    return dataset\n",
        "  \n",
        "  def group_by_sentence(self, dataset):\n",
        "    dataset_in_sentence = [list(group) for k, group in groupby(dataset, lambda x: x == \"\") if not k]\n",
        "    return dataset_in_sentence\n",
        "\n",
        "  def get_windowed_words_from_sentence(self, sentence):\n",
        "    result = []\n",
        "    for i, word in enumerate(sentence):\n",
        "      splitted_word = word.split(' ')\n",
        "      center_word = splitted_word[0]\n",
        "      label = splitted_word[-1]\n",
        "      is_organization = label in ['B-ORG', 'I-ORG']\n",
        "      \n",
        "      prev_index = max(i - window_len, 0)\n",
        "      prev_words = sentence[prev_index:i]\n",
        "      prev_words = [word_str.split(' ')[0] for word_str in prev_words]\n",
        "\n",
        "\n",
        "      next_index = i + window_len + 1\n",
        "      next_words = sentence[i+1:next_index]\n",
        "      next_words = [word_str.split(' ')[0] for word_str in next_words]\n",
        "\n",
        "      # We have to add padding, if number of prev words or next words are shorter than expected\n",
        "      if len(prev_words) != window_len:\n",
        "        prev_words = ['<pad>'] * (window_len - len(prev_words)) + prev_words\n",
        "\n",
        "      if len(next_words) != window_len:\n",
        "        next_words = next_words + ['<pad>'] * (window_len - len(next_words))\n",
        "\n",
        "      concatenated_words = prev_words + [center_word] + next_words\n",
        "      result.append( (concatenated_words, is_organization))\n",
        "    return result\n",
        "\n",
        "  def __len__(self): # number of independent data samples\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    # is called when you call dataset[idx]\n",
        "    cat_words, label = self.data[idx]\n",
        "\n",
        "    # return self.data[idx]\n",
        "    return self.convert_windowed_words_to_vector(cat_words), label\n",
        "\n",
        "  def convert_windowed_words_to_vector(self, cat_words):\n",
        "    # cat_words: list of strings\n",
        "    # e.g. ['<pad>', '<pad>', 'EU', 'rejects', 'German']\n",
        "    corresp_vectors = []\n",
        "    for word in cat_words:\n",
        "      if word.lower() in self.wrd2vec: # if the word exists in wrd2vec vocab\n",
        "        vec = self.wrd2vec[word.lower()] # call corresponding vector \n",
        "        # vec = torch.tensor(vec)\n",
        "      else: # there is no matching word in wrd2vec vocab, such as <pad>\n",
        "        # vec = torch.zeros(vec_dim)\n",
        "        vec = np.zeros(self.vec_size) # use zero vectors for that token (word)\n",
        "      corresp_vectors.append(vec)\n",
        "    return torch.tensor(np.concatenate(corresp_vectors), dtype=torch.float)\n",
        "\n",
        "dataset = Dataset(\"train.txt\", wrd2vec)"
      ],
      "metadata": {
        "id": "nPGbWxVWR_h1"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset.data), dataset.data[0]"
      ],
      "metadata": {
        "id": "hHUpjGUg9DJg",
        "outputId": "41efe4cb-d2c1-4555-edba-77ceb6d0006e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(192587, (['<pad>', '<pad>', 'EU', 'rejects', 'German'], True))"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset), dataset[0]"
      ],
      "metadata": {
        "id": "mbFSkXTb9Sql",
        "outputId": "35682f16-66bb-4aaa-c841-15eb75a085f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(192587,\n",
              " (tensor([ 0.0000,  0.0000,  0.0000,  ..., -0.1950,  0.2041,  0.3530]), True))"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[100]"
      ],
      "metadata": {
        "id": "TSWoHJco_-tY",
        "outputId": "a47d77de-e2d4-47f5-bb49-230ba8dc29fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-0.2295,  0.3255, -0.0927,  ..., -0.3422, -0.0224,  0.1368]), False)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wrd2vec.vector_size"
      ],
      "metadata": {
        "id": "Hahxf24x-9xL",
        "outputId": "a57d2299-23cb-46f0-b7c4-be4dcc776e21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Our method can make training samples from a given data_in_setence\n",
        "dataset.get_windowed_words_from_sentence(dataset.data_in_sentence[100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGhz5RwYR3BZ",
        "outputId": "b8841eea-ca86-4b8b-da55-2eb6354922c4"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(['<pad>', '<pad>', 'Israel', \"'s\", 'Channel'], False),\n",
              " (['<pad>', 'Israel', \"'s\", 'Channel', 'Two'], False),\n",
              " (['Israel', \"'s\", 'Channel', 'Two', 'television'], True),\n",
              " ([\"'s\", 'Channel', 'Two', 'television', 'said'], True),\n",
              " (['Channel', 'Two', 'television', 'said', 'Damascus'], False),\n",
              " (['Two', 'television', 'said', 'Damascus', 'had'], False),\n",
              " (['television', 'said', 'Damascus', 'had', 'sent'], False),\n",
              " (['said', 'Damascus', 'had', 'sent', 'a'], False),\n",
              " (['Damascus', 'had', 'sent', 'a', '\"'], False),\n",
              " (['had', 'sent', 'a', '\"', 'calming'], False),\n",
              " (['sent', 'a', '\"', 'calming', 'signal'], False),\n",
              " (['a', '\"', 'calming', 'signal', '\"'], False),\n",
              " (['\"', 'calming', 'signal', '\"', 'to'], False),\n",
              " (['calming', 'signal', '\"', 'to', 'Israel'], False),\n",
              " (['signal', '\"', 'to', 'Israel', '.'], False),\n",
              " (['\"', 'to', 'Israel', '.', '<pad>'], False),\n",
              " (['to', 'Israel', '.', '<pad>', '<pad>'], False)]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# use data loader\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "dataloader = DataLoader(dataset, batch_size=16, shuffle=True, drop_last=True)\n",
        "\n",
        "for batch in dataloader:\n",
        "  print(batch)\n",
        "  break"
      ],
      "metadata": {
        "id": "2HcHg0-98Wr2",
        "outputId": "738c1eb5-aa02-4e8c-baa1-864905e95460",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[-0.2456,  0.0680,  0.1825,  ..., -0.2329, -0.1223,  0.3550],\n",
            "        [-0.0702,  0.3243,  0.0081,  ..., -0.2550,  0.0078, -0.6203],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ..., -0.2004, -0.0822, -0.0626],\n",
            "        ...,\n",
            "        [-0.6533,  0.2088,  0.0180,  ..., -0.3988, -0.8299,  0.1757],\n",
            "        [-0.0268,  1.0621, -0.0129,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ..., -1.2129,  0.7766,  0.1933]]), tensor([False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False, False, False, False])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensors = batch[0]\n",
        "labels = batch[1]\n",
        "\n",
        "input_tensors.shape, labels.shape"
      ],
      "metadata": {
        "id": "GbPDJK1WA0T2",
        "outputId": "2d085bbf-194f-4194-be2c-af403e859452",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([16, 1500]), torch.Size([16]))"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check that our model can compute the input batch\n",
        "pred = model(input_tensors)\n",
        "pred.shape, pred"
      ],
      "metadata": {
        "id": "33zUbVYGBK2T",
        "outputId": "5ff249fa-64e1-442c-8b21-da4357e770ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([16, 1]), tensor([[0.4473],\n",
              "         [0.4213],\n",
              "         [0.4807],\n",
              "         [0.4716],\n",
              "         [0.4324],\n",
              "         [0.4557],\n",
              "         [0.4618],\n",
              "         [0.4389],\n",
              "         [0.4836],\n",
              "         [0.4591],\n",
              "         [0.4559],\n",
              "         [0.4601],\n",
              "         [0.4466],\n",
              "         [0.4591],\n",
              "         [0.4678],\n",
              "         [0.4732]], grad_fn=<SigmoidBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels.dtype, labels, labels.float()"
      ],
      "metadata": {
        "id": "4VwcsEDnDJwA",
        "outputId": "3a3c5edc-2636-4157-cbbe-75e6817587f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.bool,\n",
              " tensor([False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False]),\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pred)\n",
        "print(pred.squeeze())"
      ],
      "metadata": {
        "id": "n17fWx4IDgGQ",
        "outputId": "75225475-2324-4130-eddf-53d0aa94c0eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4473],\n",
            "        [0.4213],\n",
            "        [0.4807],\n",
            "        [0.4716],\n",
            "        [0.4324],\n",
            "        [0.4557],\n",
            "        [0.4618],\n",
            "        [0.4389],\n",
            "        [0.4836],\n",
            "        [0.4591],\n",
            "        [0.4559],\n",
            "        [0.4601],\n",
            "        [0.4466],\n",
            "        [0.4591],\n",
            "        [0.4678],\n",
            "        [0.4732]], grad_fn=<SigmoidBackward0>)\n",
            "tensor([0.4473, 0.4213, 0.4807, 0.4716, 0.4324, 0.4557, 0.4618, 0.4389, 0.4836,\n",
            "        0.4591, 0.4559, 0.4601, 0.4466, 0.4591, 0.4678, 0.4732],\n",
            "       grad_fn=<SqueezeBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate loss\n",
        "print(pred.shape, labels.shape)\n",
        "\n",
        "def get_binary_cross_entropy_loss(pred, label):\n",
        "  return label * (-torch.log(pred)) + (1-label) * (-torch.log(1-pred))\n",
        "\n",
        "loss = get_binary_cross_entropy_loss(pred.squeeze(), labels.float())\n",
        "loss = loss.mean() # take mean\n",
        "loss"
      ],
      "metadata": {
        "id": "iiuVTxHBBbwx",
        "outputId": "d1a82bf3-3e07-46a4-d24f-78c3595aebe8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 1]) torch.Size([16])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.6115, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check how gradient looks like before the backpropagation\n",
        "print(model.layer1.weight.grad) # print None"
      ],
      "metadata": {
        "id": "_5keVatqD5oY",
        "outputId": "9e6a92a0-d06a-4741-ba44-4c6a722cbc0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# backpropagate the loss \n",
        "loss.backward()"
      ],
      "metadata": {
        "id": "z5PoLCdiDxqI"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check how gradient looks like after the backpropagation\n",
        "print(model.layer1.weight.grad)"
      ],
      "metadata": {
        "id": "LEbe0q7mEDEL",
        "outputId": "f5502ee0-587e-42c9-883a-1c7a856211e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 7.3340e-03, -1.1900e-02, -9.1739e-04,  ...,  1.2517e-02,\n",
            "         -2.4642e-03,  1.0083e-03],\n",
            "        [-1.5112e-03,  1.8738e-03,  1.3736e-03,  ..., -1.9040e-03,\n",
            "         -2.5207e-05,  1.3174e-03],\n",
            "        [-3.2698e-03,  2.6332e-03, -7.1477e-05,  ..., -8.9265e-03,\n",
            "          1.2005e-03,  1.9822e-03],\n",
            "        ...,\n",
            "        [-6.9544e-03,  1.2590e-02, -1.8057e-03,  ..., -1.2442e-02,\n",
            "          3.1392e-04, -3.0374e-03],\n",
            "        [ 3.0124e-03, -5.6204e-03,  1.3385e-03,  ...,  7.1443e-03,\n",
            "          8.1332e-04,  2.6787e-04],\n",
            "        [-1.9728e-04, -3.6963e-04, -9.7506e-06,  ...,  3.8729e-03,\n",
            "          1.2328e-04, -1.8352e-04]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.layer1.weight.grad.shape, model.layer1.weight.shape"
      ],
      "metadata": {
        "id": "hdgqNLryEJSk",
        "outputId": "7c2bc0cf-22d0-4700-d1f2-a62b4649c225",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 1500]), torch.Size([32, 1500]))"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# manual update\n",
        "model.layer1.weight.data -= model.layer1.weight.grad * 0.001"
      ],
      "metadata": {
        "id": "Mn2aK17oEWl3",
        "outputId": "9e80dc69-6d83-4844-8a61-1cf5e6846f57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-85-1ff0bf90283b>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    model.layer1.\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# use torch.optim.optimizers"
      ],
      "metadata": {
        "id": "twraLTiAEZdA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "nbformat": 4,
    "nbformat_minor": 5,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}